[General]
output = /path/to/output
trainingVariables = variable0,variable1,variable2
samples = Sample1
testPercentage = 0.2

[Sample1]
input = /path/to/input.h5
label = Sample1Label
datatype = data

[NeuralNet]
activation = relu
outputActivation = softmax
name = DefaultDNN
optimizer = adagrad
inputDimention = 10
epochs = 10
loss = categorical_crossentropy

